// components/panels/SettingsPanel.js
// LLM ì„¤ì • ë° ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ëŠ” ë°±ì—”ë“œì—ì„œ ì¤‘ì•™ ê´€ë¦¬ë©ë‹ˆë‹¤.
import { useEffect, useMemo, useState, useCallback } from "react";

const DEFAULT_FALLBACK_SYSTEM_PROMPT = "[í”„ë¡¬í”„íŠ¸ë¥¼ ì„¤ì •í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤]";

const clampNumber = (v, min, max, fallback) => {
  const n = Number(v);
  if (!Number.isFinite(n)) return fallback;
  if (typeof min === "number" && n < min) return min;
  if (typeof max === "number" && n > max) return max;
  return n;
};

// í”„ë¦¬ì…‹ ì„¤ì •
const LLM_PRESETS = {
  precise: {
    name: "ì •í™•í•œ ì‘ë‹µ",
    description: "ë¶„ì„/ë°ì´í„° ì‘ì—…ì— ì í•©",
    icon: "ğŸ¯",
    temperature: 0.1,
    topP: 0.9,
    presencePenalty: 0.0,
    frequencyPenalty: 0.0,
  },
  balanced: {
    name: "ê· í˜•ì¡íŒ",
    description: "ì¼ë°˜ì ì¸ ëŒ€í™”ì— ì í•©",
    icon: "âš–ï¸",
    temperature: 0.5,
    topP: 1.0,
    presencePenalty: 0.0,
    frequencyPenalty: 0.0,
  },
  creative: {
    name: "ì°½ì˜ì ",
    description: "ì•„ì´ë””ì–´/ìŠ¤í† ë¦¬í…”ë§ì— ì í•©",
    icon: "âœ¨",
    temperature: 0.9,
    topP: 1.0,
    presencePenalty: 0.3,
    frequencyPenalty: 0.2,
  },
};

// ìŠ¬ë¼ì´ë” ì»´í¬ë„ŒíŠ¸
function Slider({ value, onChange, min, max, step, label, disabled, showValue = true }) {
  const percentage = ((value - min) / (max - min)) * 100;

  return (
    <div className="relative">
      <div className="flex items-center justify-between mb-1">
        <label className="text-sm text-cookie-brown/70">{label}</label>
        {showValue && (
          <span className="text-sm font-mono text-cookie-brown/80">{value.toFixed(step < 1 ? 2 : 0)}</span>
        )}
      </div>
      <div className="relative h-2 bg-cookie-cream rounded-full overflow-hidden">
        <div
          className="absolute h-full bg-gradient-to-r from-cookie-orange to-cookie-pink transition-all duration-150"
          style={{ width: `${percentage}%` }}
        />
      </div>
      <input
        type="range"
        min={min}
        max={max}
        step={step}
        value={value}
        disabled={disabled}
        onChange={(e) => onChange(parseFloat(e.target.value))}
        className="absolute inset-0 w-full h-full opacity-0 cursor-pointer disabled:cursor-not-allowed"
        style={{ top: '20px', height: '8px' }}
      />
    </div>
  );
}

export default function SettingsPanel({ settings, setSettings, addLog, apiCall, auth }) {
  // âœ… GPT-4 ê³„ì—´ ì¤‘ì‹¬ + í•„ìš”ì‹œ í™•ì¥
  const models = useMemo(
    () => [
      "gpt-4o",
      "gpt-4o-mini",
      "gpt-4.1",
      "gpt-4.1-mini",
      "gpt-4-turbo",
    ],
    []
  );

  // í”„ë¡¬í”„íŠ¸ ê´€ë ¨ ìƒíƒœ
  const [loadingDefault, setLoadingDefault] = useState(false);
  const [draftPrompt, setDraftPrompt] = useState(settings?.systemPrompt || "");
  const [promptSaved, setPromptSaved] = useState(true);
  const [isCustomPrompt, setIsCustomPrompt] = useState(false);

  // LLM ì„¤ì • ê´€ë ¨ ìƒíƒœ
  const [llmSaving, setLlmSaving] = useState(false);
  const [llmSaved, setLlmSaved] = useState(true);
  const [isCustomLLM, setIsCustomLLM] = useState(false);
  const [promptSaving, setPromptSaving] = useState(false);

  // LLM ì„¤ì • ì„ì‹œ ìƒíƒœ (ì €ì¥ ë²„íŠ¼ ëˆ„ë¥´ê¸° ì „ê¹Œì§€ ì—¬ê¸°ì—ë§Œ ì €ì¥)
  const [draftLLM, setDraftLLM] = useState({
    selectedModel: settings?.selectedModel || "gpt-4o-mini",
    customModel: settings?.customModel || "",
    temperature: settings?.temperature ?? 0.3,
    topP: settings?.topP ?? 1.0,
    presencePenalty: settings?.presencePenalty ?? 0.0,
    frequencyPenalty: settings?.frequencyPenalty ?? 0.0,
    maxTokens: settings?.maxTokens ?? 4000,
    seed: settings?.seed ?? "",
    timeoutMs: settings?.timeoutMs ?? 30000,
    retries: settings?.retries ?? 2,
    stream: settings?.stream ?? true,
    apiKey: settings?.apiKey ?? "",
  });

  // draftLLM ê¸°ë°˜ íŒŒìƒ ê°’ (useState ì´í›„ì— ìœ„ì¹˜í•´ì•¼ í•¨)
  const selectedModel = (draftLLM?.selectedModel || "gpt-4o-mini").trim();
  const isGpt5 = selectedModel.toLowerCase().startsWith("gpt-5");
  const isMiniModel = selectedModel.toLowerCase().includes("mini");
  const maxTokensLimit = isMiniModel ? 16000 : 4500;

  // settings.systemPromptê°€ ì™¸ë¶€ì—ì„œ ë³€ê²½ë˜ë©´ draftPrompt ë™ê¸°í™”
  useEffect(() => {
    setDraftPrompt(settings?.systemPrompt || "");
    setPromptSaved(true);
  }, [settings?.systemPrompt]);

  // settingsê°€ ì™¸ë¶€ì—ì„œ ë³€ê²½ë˜ë©´ draftLLM ë™ê¸°í™”
  useEffect(() => {
    setDraftLLM({
      selectedModel: settings?.selectedModel || "gpt-4o-mini",
      customModel: settings?.customModel || "",
      temperature: settings?.temperature ?? 0.3,
      topP: settings?.topP ?? 1.0,
      presencePenalty: settings?.presencePenalty ?? 0.0,
      frequencyPenalty: settings?.frequencyPenalty ?? 0.0,
      maxTokens: settings?.maxTokens ?? 4000,
      seed: settings?.seed ?? "",
      timeoutMs: settings?.timeoutMs ?? 30000,
      retries: settings?.retries ?? 2,
      stream: settings?.stream ?? true,
      apiKey: settings?.apiKey ?? "",
    });
    setLlmSaved(true);
  }, []);

  // ============================================================
  // ë°±ì—”ë“œì—ì„œ LLM ì„¤ì • ë¡œë“œ
  // ============================================================
  const loadLLMSettingsFromBackend = useCallback(async () => {
    if (typeof apiCall !== "function") return;

    try {
      const res = await apiCall({
        endpoint: "/api/settings/llm",
        method: "GET",
        auth,
        timeoutMs: 30000,
      });

      const data = res?.data || res || {};
      setIsCustomLLM(Boolean(data?.isCustom));

      // ì„¤ì •ê°’ ë³‘í•©
      setSettings((s) => ({
        ...s,
        selectedModel: data?.selectedModel || s?.selectedModel || "gpt-4o-mini",
        customModel: data?.customModel || s?.customModel || "",
        temperature: data?.temperature ?? s?.temperature ?? 0.3,
        topP: data?.topP ?? s?.topP ?? 1.0,
        presencePenalty: data?.presencePenalty ?? s?.presencePenalty ?? 0.0,
        frequencyPenalty: data?.frequencyPenalty ?? s?.frequencyPenalty ?? 0.0,
        maxTokens: data?.maxTokens ?? s?.maxTokens ?? 4000,
        seed: data?.seed ?? s?.seed ?? "",
        timeoutMs: data?.timeoutMs ?? s?.timeoutMs ?? 30000,
        retries: data?.retries ?? s?.retries ?? 2,
        stream: data?.stream ?? s?.stream ?? true,
      }));
      setLlmSaved(true);
    } catch (e) {
      console.error("LLM ì„¤ì • ë¡œë“œ ì‹¤íŒ¨:", e);
    }
  }, [apiCall, auth, setSettings]);

  // ë°±ì—”ë“œì—ì„œ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ë¡œë“œ
  const loadPromptFromBackend = useCallback(async () => {
    if (typeof apiCall !== "function") return;

    setLoadingDefault(true);
    try {
      const res = await apiCall({
        endpoint: "/api/settings/prompt",
        method: "GET",
        auth,
        timeoutMs: 30000,
      });

      const data = res?.data || res || {};
      const prompt = String(data?.systemPrompt || data?.system_prompt || "").trim();
      const isCustom = Boolean(data?.isCustom);

      setIsCustomPrompt(isCustom);

      if (prompt.length > 0) {
        setSettings((s) => ({ ...s, systemPrompt: prompt }));
        setDraftPrompt(prompt);
      }
    } catch (e) {
      console.error("í”„ë¡¬í”„íŠ¸ ë¡œë“œ ì‹¤íŒ¨:", e);
    } finally {
      setLoadingDefault(false);
    }
  }, [apiCall, auth, setSettings]);

  // ì´ˆê¸° ë¡œë“œ - localStorage ê°’ ìœ ì§€ (ë°±ì—”ë“œ API í˜¸ì¶œ ì œê±°)
  // RailwayëŠ” ephemeral íŒŒì¼ ì‹œìŠ¤í…œì´ë¼ ë°±ì—”ë“œ ì €ì¥ì´ ìœ ì§€ë˜ì§€ ì•ŠìŒ
  // í”„ë¡ íŠ¸ì—”ë“œ localStorageì—ì„œë§Œ ì„¤ì • ê´€ë¦¬
  useEffect(() => {
    // ë°±ì—”ë“œ ë¡œë“œ ì œê±° - localStorage ê°’ ê·¸ëŒ€ë¡œ ì‚¬ìš©
    // loadLLMSettingsFromBackend();
    // loadPromptFromBackend();
    setLlmSaved(true); // ë¡œì»¬ ì €ì¥ ìƒíƒœë¡œ ì‹œì‘
  }, []);

  // ============================================================
  // ë°±ì—”ë“œì— LLM ì„¤ì • ì €ì¥
  // ============================================================
  const saveLLMSettingsToBackend = useCallback(async () => {
    if (typeof apiCall !== "function") {
      // ë°±ì—”ë“œ ì—°ê²° ì—†ìœ¼ë©´ ë¡œì»¬ë§Œ ì €ì¥
      setLlmSaved(true);
      if (addLog) addLog("LLM ì„¤ì • ë³€ê²½", "ë¡œì»¬ ì €ì¥ë¨ (ë°±ì—”ë“œ ì—°ê²° ì—†ìŒ)");
      return;
    }

    setLlmSaving(true);
    try {
      const res = await apiCall({
        endpoint: "/api/settings/llm",
        method: "POST",
        auth,
        body: {
          selectedModel: settings?.selectedModel || "gpt-4o-mini",
          customModel: settings?.customModel || "",
          temperature: settings?.temperature ?? 0.3,
          topP: settings?.topP ?? 1.0,
          presencePenalty: settings?.presencePenalty ?? 0.0,
          frequencyPenalty: settings?.frequencyPenalty ?? 0.0,
          maxTokens: settings?.maxTokens ?? 4000,
          seed: settings?.seed || null,
          timeoutMs: settings?.timeoutMs ?? 30000,
          retries: settings?.retries ?? 2,
          stream: settings?.stream ?? true,
        },
        timeoutMs: 30000,
      });

      if (res?.status === "SUCCESS") {
        setLlmSaved(true);
        setIsCustomLLM(true);
        if (addLog) addLog("LLM ì„¤ì • ë³€ê²½", `ë°±ì—”ë“œì— ì €ì¥ë¨ (ëª¨ë¸: ${settings?.selectedModel})`);
      } else {
        throw new Error(res?.message || "ì €ì¥ ì‹¤íŒ¨");
      }
    } catch (e) {
      console.error("LLM ì„¤ì • ì €ì¥ ì‹¤íŒ¨:", e);
      // ì €ì¥ ì‹¤íŒ¨ ì‹œ ì‚¬ìš©ìì—ê²Œ ì•Œë¦¼
      const errorMsg = e?.message || "ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜";
      alert(`âŒ LLM ì„¤ì • ì €ì¥ ì‹¤íŒ¨: ${errorMsg}\n\nê´€ë¦¬ì(admin) ê³„ì •ìœ¼ë¡œ ë¡œê·¸ì¸í–ˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.`);
      setLlmSaved(false); // ì €ì¥ ì‹¤íŒ¨ ìƒíƒœ ìœ ì§€
      if (addLog) addLog("LLM ì„¤ì • ì €ì¥ ì‹¤íŒ¨", errorMsg);
    } finally {
      setLlmSaving(false);
    }
  }, [apiCall, auth, settings, addLog]);

  // LLM ì„¤ì • ì´ˆê¸°í™”
  const resetLLMSettingsToDefault = useCallback(async () => {
    if (typeof apiCall !== "function") return;

    setLlmSaving(true);
    try {
      const res = await apiCall({
        endpoint: "/api/settings/llm/reset",
        method: "POST",
        auth,
        timeoutMs: 30000,
      });

      if (res?.status === "SUCCESS") {
        const data = res?.data || {};
        setSettings((s) => ({
          ...s,
          selectedModel: data?.selectedModel || "gpt-4o-mini",
          customModel: data?.customModel || "",
          temperature: data?.temperature ?? 0.3,
          topP: data?.topP ?? 1.0,
          presencePenalty: data?.presencePenalty ?? 0.0,
          frequencyPenalty: data?.frequencyPenalty ?? 0.0,
          maxTokens: data?.maxTokens ?? 4000,
          seed: data?.seed ?? "",
          timeoutMs: data?.timeoutMs ?? 30000,
          retries: data?.retries ?? 2,
          stream: data?.stream ?? true,
        }));
        setLlmSaved(true);
        setIsCustomLLM(false);
        if (addLog) addLog("LLM ì„¤ì • ì´ˆê¸°í™”", "ê¸°ë³¸ê°’ìœ¼ë¡œ ì´ˆê¸°í™”ë¨");
      }
    } catch (e) {
      console.error("LLM ì„¤ì • ì´ˆê¸°í™” ì‹¤íŒ¨:", e);
      if (addLog) addLog("LLM ì„¤ì • ì´ˆê¸°í™”", `ì‹¤íŒ¨: ${e.message}`);
    } finally {
      setLlmSaving(false);
    }
  }, [apiCall, auth, setSettings, addLog]);

  // ë°±ì—”ë“œì— ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ì €ì¥
  const savePromptToBackend = useCallback(async () => {
    if (typeof apiCall !== "function") {
      // ë°±ì—”ë“œ ì—°ê²° ì—†ìœ¼ë©´ ë¡œì»¬ë§Œ ì €ì¥
      setSettings((s) => ({ ...s, systemPrompt: draftPrompt }));
      setPromptSaved(true);
      if (addLog) addLog("í”„ë¡¬í”„íŠ¸ ë³€ê²½", "ë¡œì»¬ ì €ì¥ë¨ (ë°±ì—”ë“œ ì—°ê²° ì—†ìŒ)");
      return;
    }

    setPromptSaving(true);
    try {
      const res = await apiCall({
        endpoint: "/api/settings/prompt",
        method: "POST",
        auth,
        body: { systemPrompt: draftPrompt },
        timeoutMs: 30000,
      });

      if (res?.status === "SUCCESS") {
        setSettings((s) => ({ ...s, systemPrompt: draftPrompt }));
        setPromptSaved(true);
        setIsCustomPrompt(true);
        if (addLog) addLog("í”„ë¡¬í”„íŠ¸ ë³€ê²½", "ë°±ì—”ë“œì— ì €ì¥ë¨");
      } else {
        throw new Error(res?.message || "ì €ì¥ ì‹¤íŒ¨");
      }
    } catch (e) {
      console.error("í”„ë¡¬í”„íŠ¸ ì €ì¥ ì‹¤íŒ¨:", e);
      // ë°±ì—”ë“œ ì €ì¥ ì‹¤íŒ¨í•´ë„ ë¡œì»¬ì—ëŠ” ì €ì¥
      setSettings((s) => ({ ...s, systemPrompt: draftPrompt }));
      setPromptSaved(true);
      if (addLog) addLog("í”„ë¡¬í”„íŠ¸ ë³€ê²½", `ë¡œì»¬ ì €ì¥ë¨ (ë°±ì—”ë“œ ì˜¤ë¥˜: ${e.message})`);
    } finally {
      setPromptSaving(false);
    }
  }, [apiCall, auth, draftPrompt, setSettings, addLog]);

  // ê¸°ë³¸ê°’ìœ¼ë¡œ ì´ˆê¸°í™”
  const resetPromptToDefault = useCallback(async () => {
    if (typeof apiCall !== "function") return;

    setPromptSaving(true);
    try {
      const res = await apiCall({
        endpoint: "/api/settings/prompt/reset",
        method: "POST",
        auth,
        timeoutMs: 30000,
      });

      if (res?.status === "SUCCESS") {
        const defaultPrompt = res?.data?.systemPrompt || DEFAULT_FALLBACK_SYSTEM_PROMPT;
        setSettings((s) => ({ ...s, systemPrompt: defaultPrompt }));
        setDraftPrompt(defaultPrompt);
        setPromptSaved(true);
        setIsCustomPrompt(false);
        if (addLog) addLog("í”„ë¡¬í”„íŠ¸ ì´ˆê¸°í™”", "ê¸°ë³¸ê°’ìœ¼ë¡œ ì´ˆê¸°í™”ë¨");
      }
    } catch (e) {
      console.error("í”„ë¡¬í”„íŠ¸ ì´ˆê¸°í™” ì‹¤íŒ¨:", e);
      if (addLog) addLog("í”„ë¡¬í”„íŠ¸ ì´ˆê¸°í™”", `ì‹¤íŒ¨: ${e.message}`);
    } finally {
      setPromptSaving(false);
    }
  }, [apiCall, auth, setSettings, addLog]);

  // LLM ì„¤ì • ë³€ê²½ ê°ì§€ - draftì—ë§Œ ì €ì¥ (ì €ì¥ ë²„íŠ¼ ëˆ„ë¥´ê¸° ì „)
  const handleLLMSettingChange = useCallback((key, value) => {
    setDraftLLM((d) => {
      const updated = { ...d, [key]: value };

      // ëª¨ë¸ ë³€ê²½ ì‹œ maxTokens ìë™ ì¡°ì •
      if (key === "selectedModel") {
        const isMini = value.toLowerCase().includes("mini");
        const newLimit = isMini ? 16000 : 4500;
        // í˜„ì¬ maxTokensê°€ ìƒˆ í•œë„ë¥¼ ì´ˆê³¼í•˜ë©´ ê¸°ë³¸ê°’ìœ¼ë¡œ ì¡°ì •
        if (d.maxTokens > newLimit) {
          updated.maxTokens = isMini ? 8000 : 4000;
        }
      }

      return updated;
    });
    setLlmSaved(false); // ë³€ê²½ì‚¬í•­ ìˆìŒ í‘œì‹œ
  }, []);

  // ì €ì¥ ë²„íŠ¼ í´ë¦­ ì‹œ ì‹¤ì œ settingsì— ë°˜ì˜
  const saveLLMSettings = useCallback(() => {
    setSettings((s) => ({ ...s, ...draftLLM }));
    setLlmSaved(true);
    if (addLog) addLog("LLM ì„¤ì • ì €ì¥", `ëª¨ë¸: ${draftLLM.selectedModel}`);
  }, [draftLLM, setSettings, addLog]);

  return (
    <div>
      <div className="flex items-end justify-between gap-3 mb-3">
        <div>
          <h2 className="text-lg md:text-xl font-semibold text-cookie-brown">LLM ì„¤ì •</h2>
          <p className="text-sm text-cookie-brown/60">ëª¨ë¸ íŒŒë¼ë¯¸í„° ì„¤ì •</p>
        </div>
        <span className="badge">Admin</span>
      </div>

      <div className="grid grid-cols-1 lg:grid-cols-2 gap-4">
        <div className="card">
          <div className="card-header flex items-center justify-between">
            <div className="flex items-center gap-2">
              <span>ëª¨ë¸ íŒŒë¼ë¯¸í„°</span>
              {isCustomLLM ? (
                <span className="text-xs px-2 py-0.5 rounded-full bg-cookie-orange/20 text-cookie-orange">ì»¤ìŠ¤í…€</span>
              ) : (
                <span className="text-xs px-2 py-0.5 rounded-full bg-gray-200 text-gray-600">ê¸°ë³¸ê°’</span>
              )}
            </div>
            {!llmSaved && (
              <span className="text-xs text-cookie-orange font-medium">ë³€ê²½ì‚¬í•­ ìˆìŒ</span>
            )}
          </div>

          <div className="space-y-3">
            <div>
              <label className="text-sm text-cookie-brown/70">ëª¨ë¸</label>
              <select
                className="input mt-1"
                value={selectedModel}
                onChange={(e) => handleLLMSettingChange("selectedModel", e.target.value)}
              >
                {models.map((m) => (
                  <option key={m} value={m}>
                    {m}
                  </option>
                ))}
              </select>

              <div className="mt-2">
                <label className="text-xs text-cookie-brown/60">ëª¨ë¸ëª… ì§ì ‘ ì…ë ¥(ì„ íƒ) <span className="text-cookie-brown/40">(ë¹„í™œì„±)</span></label>
                <input
                  className="input mt-1 opacity-60 cursor-not-allowed"
                  type="text"
                  value={draftLLM?.customModel ?? ""}
                  placeholder="ì˜ˆ: gpt-4o (ë¹„ìš°ë©´ ìœ„ ì„ íƒê°’ ì‚¬ìš©)"
                  disabled
                />
              </div>
            </div>

            {/* í”„ë¦¬ì…‹ ë²„íŠ¼ */}
            <div>
              <label className="text-sm text-cookie-brown/70 mb-2 block">ë¹ ë¥¸ í”„ë¦¬ì…‹</label>
              <div className="grid grid-cols-3 gap-2">
                {Object.entries(LLM_PRESETS).map(([key, preset]) => (
                  <button
                    key={key}
                    className="p-2 rounded-lg border-2 border-cookie-cream hover:border-cookie-orange/50 bg-white hover:bg-cookie-cream/30 transition-all text-left group"
                    onClick={() => {
                      setDraftLLM((d) => ({
                        ...d,
                        temperature: preset.temperature,
                        topP: preset.topP,
                        presencePenalty: preset.presencePenalty,
                        frequencyPenalty: preset.frequencyPenalty,
                      }));
                      setLlmSaved(false);
                    }}
                  >
                    <div className="text-lg mb-1">{preset.icon}</div>
                    <div className="text-xs font-medium text-cookie-brown group-hover:text-cookie-orange transition-colors">{preset.name}</div>
                    <div className="text-[10px] text-cookie-brown/50">{preset.description}</div>
                  </button>
                ))}
              </div>
            </div>

            <div className="grid grid-cols-1 sm:grid-cols-2 gap-4">
              <div>
                <Slider
                  label="Temperature"
                  value={draftLLM?.temperature ?? 0.3}
                  onChange={(v) => handleLLMSettingChange("temperature", v)}
                  min={0}
                  max={2}
                  step={0.1}
                  disabled={isGpt5}
                />
                {isGpt5 ? <div className="text-xs text-cookie-brown/60 mt-1">gpt-5 ê³„ì—´ì€ temperatureë¥¼ ì‚¬ìš©í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.</div> : null}
                <div className="text-xs text-cookie-brown/50 mt-1">ë‚®ì„ìˆ˜ë¡ ì •í™•, ë†’ì„ìˆ˜ë¡ ì°½ì˜ì </div>
              </div>

              <div>
                <Slider
                  label="Top P"
                  value={draftLLM?.topP ?? 1}
                  onChange={(v) => handleLLMSettingChange("topP", v)}
                  min={0}
                  max={1}
                  step={0.05}
                />
                <div className="text-xs text-cookie-brown/50 mt-1">í™•ë¥  ë¶„í¬ ì»¤íŠ¸ë¼ì¸</div>
              </div>
            </div>

            <div className="grid grid-cols-1 sm:grid-cols-2 gap-4">
              <div>
                <Slider
                  label="Presence Penalty"
                  value={draftLLM?.presencePenalty ?? 0}
                  onChange={(v) => handleLLMSettingChange("presencePenalty", v)}
                  min={-2}
                  max={2}
                  step={0.1}
                />
                <div className="text-xs text-cookie-brown/50 mt-1">ìƒˆ ì£¼ì œ ì–¸ê¸‰ ìœ ë„</div>
              </div>

              <div>
                <Slider
                  label="Frequency Penalty"
                  value={draftLLM?.frequencyPenalty ?? 0}
                  onChange={(v) => handleLLMSettingChange("frequencyPenalty", v)}
                  min={-2}
                  max={2}
                  step={0.1}
                />
                <div className="text-xs text-cookie-brown/50 mt-1">ë°˜ë³µ í‘œí˜„ ì–µì œ</div>
              </div>
            </div>

            <div className="grid grid-cols-1 sm:grid-cols-2 gap-3">
              <div>
                <label className="text-sm text-cookie-brown/70">Max Tokens {isMiniModel ? "(ìµœëŒ€ 16000)" : "(ìµœëŒ€ 4500)"}</label>
                <input
                  className="input mt-1"
                  type="number"
                  step="100"
                  min="100"
                  max={maxTokensLimit}
                  value={draftLLM?.maxTokens ?? (isMiniModel ? 8000 : 4000)}
                  onChange={(e) => handleLLMSettingChange("maxTokens", clampNumber(e.target.value, 100, maxTokensLimit, isMiniModel ? 8000 : 4000))}
                />
              </div>

              <div>
                <label className="text-sm text-cookie-brown/70">Seed (ì„ íƒ)</label>
                <input
                  className="input mt-1"
                  type="number"
                  step="1"
                  min="0"
                  value={draftLLM?.seed ?? ""}
                  placeholder="ë¹„ìš°ë©´ ë¯¸ì‚¬ìš©"
                  onChange={(e) => handleLLMSettingChange("seed", e.target.value === "" ? "" : clampNumber(e.target.value, 0, 2147483647, 0))}
                />
              </div>
            </div>

            <div className="grid grid-cols-1 sm:grid-cols-2 gap-3">
              <div>
                <label className="text-sm text-cookie-brown/70">ìš”ì²­ Timeout(ms)</label>
                <input
                  className="input mt-1"
                  type="number"
                  step="1000"
                  min="1000"
                  max="120000"
                  value={draftLLM?.timeoutMs ?? 30000}
                  onChange={(e) => handleLLMSettingChange("timeoutMs", clampNumber(e.target.value, 1000, 120000, 30000))}
                />
              </div>

              <div>
                <label className="text-sm text-cookie-brown/70">Retry íšŸìˆ˜</label>
                <input
                  className="input mt-1"
                  type="number"
                  step="1"
                  min="0"
                  max="10"
                  value={draftLLM?.retries ?? 2}
                  onChange={(e) => handleLLMSettingChange("retries", clampNumber(e.target.value, 0, 10, 2))}
                />
              </div>
            </div>

            <div className="flex items-center justify-between gap-3">
              <div>
                <div className="text-sm text-cookie-brown/70">ìŠ¤íŠ¸ë¦¬ë° ì‚¬ìš©</div>
                <div className="text-xs text-cookie-brown/60">UIì—ì„œ /api/agent/stream ì‚¬ìš© ì—¬ë¶€ í”Œë˜ê·¸</div>
              </div>
              <input
                type="checkbox"
                className="toggle"
                checked={Boolean(draftLLM?.stream ?? true)}
                onChange={(e) => handleLLMSettingChange("stream", e.target.checked)}
              />
            </div>

            <div>
              <label className="text-sm text-cookie-brown/70">OpenAI API Key (ë¡œì»¬ ì „ìš©)</label>
              <input
                className="input mt-1"
                type="password"
                value={draftLLM?.apiKey ?? ""}
                onChange={(e) => handleLLMSettingChange("apiKey", e.target.value)}
              />
              <div className="text-xs text-cookie-brown/50 mt-1">API KeyëŠ” ë³´ì•ˆìƒ ë¡œì»¬ì—ë§Œ ì €ì¥ë©ë‹ˆë‹¤.</div>
            </div>

            <div className="flex gap-2">
              <button
                className={`flex-1 ${llmSaved ? 'btn-secondary' : 'btn-primary'}`}
                onClick={saveLLMSettings}
                disabled={llmSaved}
              >
                {llmSaved ? 'ì €ì¥ë¨' : 'ì„¤ì • ì €ì¥'}
              </button>
            </div>
            <p className="text-xs text-cookie-brown/50">
              * ì €ì¥ ë²„íŠ¼ì„ ëˆŒëŸ¬ì•¼ ì„¤ì •ì´ ë¸Œë¼ìš°ì €ì— ì €ì¥ë©ë‹ˆë‹¤.
              <br />* AI ì—ì´ì „íŠ¸ í˜¸ì¶œ ì‹œ ì €ì¥ëœ ì„¤ì •ê°’ì´ ì ìš©ë©ë‹ˆë‹¤.
            </p>
          </div>
        </div>

        <div className="card opacity-60">
          <div className="card-header flex items-center justify-between">
            <div className="flex items-center gap-2">
              <span>ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸</span>
              <span className="text-xs px-2 py-0.5 rounded-full bg-gray-200 text-gray-600">ë¹„í™œì„±í™”ë¨</span>
            </div>
          </div>
          <textarea
            className="input cursor-not-allowed"
            style={{ height: 280 }}
            value={draftPrompt}
            placeholder="ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ì„¤ì •ì´ ë¹„í™œì„±í™”ë˜ì—ˆìŠµë‹ˆë‹¤"
            disabled
          />
          <div className="flex gap-2 mt-3">
            <button
              className="flex-1 btn-secondary opacity-50 cursor-not-allowed"
              disabled
            >
              ì €ì¥ (ë¹„í™œì„±í™”ë¨)
            </button>
          </div>
          <p className="text-xs text-cookie-brown/50 mt-2">
            * ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ì„¤ì •ì´ ë¹„í™œì„±í™”ë˜ì–´ ìˆìŠµë‹ˆë‹¤. í™œì„±í™”ê°€ í•„ìš”í•˜ë©´ ê´€ë¦¬ìì—ê²Œ ë¬¸ì˜í•˜ì„¸ìš”.
          </p>
        </div>
      </div>
    </div>
  );
}
